{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import Dict, List, Optional\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser, PydanticOutputParser\n",
    "from pydantic import BaseModel, Field, validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU \"langchain[groq]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_chat_model(\"llama-3.3-70b-versatile\", model_provider=\"groq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, TypedDict, Annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    question: str\n",
    "    decision: str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class LeadDetails(BaseModel):\n",
    "    \"Complete details of a lead in a CRM system.\"\n",
    "    salutation: Optional[str] = Field(default='null', pattern=\"^(Mr|Mrs|Ms|Dr)$\", description=\"Salutation of the lead.\")\n",
    "    first_name: str = Field(..., min_length=2, max_length=50, description=\"First name of the lead.\")\n",
    "    last_name: str = Field(..., min_length=2, max_length=50, description=\"Last name of the lead.\")\n",
    "    company: str = Field(..., max_length=100, description=\"Company name of the lead.\")\n",
    "    email: str = Field(..., pattern=r\"^\\S+@\\S+\\.\\S+$\", description=\"Email address of the lead.\")\n",
    "    gender: Optional[str] = Field(default='null', pattern=\"^(Male|Female|Other)$\")\n",
    "    lead_source: Optional[str] = Field(default='null', description=\"Lead source of the lead.\")\n",
    "    lead_score: Optional[int] = Field(default=0, ge=0, le=100, description=\"Lead score of the lead.\")\n",
    "    lead_value: Optional[str] = Field(default='null', ge=0, description=\"Lead value of the lead.\")\n",
    "    website: Optional[str] = Field(default='null', description=\"Website of the lead.\")\n",
    "    status: str = Field(default='new', pattern=\"^(new|contacted|qualified|lost)$\", description=\"Status of the lead.\")\n",
    "    converted: Optional[int] = Field(default=0, description=\"Converted status of the lead.\")\n",
    "    revenue: Optional[int] = Field(default=0, ge=0, description=\"Revenue of the lead.\")\n",
    "    company_constitution: Optional[str] = Field(default='null', description=\"Company constitution of the lead.\")\n",
    "    company_incorporation_date: Optional[str] = Field(default='null', description=\"Company incorporation date of the lead.\")\n",
    "    mobile_code: Optional[str] = Field(default='null', description=\"Mobile code of the lead.\")\n",
    "    mobile_no: Optional[str] = Field(default='null', min_length=10, max_length=15, description=\"Mobile number of the lead.\")\n",
    "    employees: Optional[int] = Field(default=0, ge=0, description=\"Number of employees of the lead.\")\n",
    "    territory_id: Optional[str] = Field(default='null', description=\"Territory ID of the lead.\")\n",
    "    industry_id: Optional[str] = Field(default='null', description=\"Industry ID of the lead.\")\n",
    "    department_id: Optional[str] = Field(default='null', description=\"Department ID of the lead.\")\n",
    "    \n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=LeadDetails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_parser():\n",
    "    \n",
    "    parser = JsonOutputParser(pydantic_object=LeadDetails)\n",
    "    llm = init_chat_model(\"llama-3.3-70b-versatile\", model_provider=\"groq\")\n",
    "    prompt = ChatPromptTemplate([\n",
    "    (\"system\",\"\"\"You Are a CRM system details: extraxter agent you need to collect the following details from the given user query.\\n\\n\n",
    "    1. First Name: \n",
    "    2. Last Name: \n",
    "    3. Company: \n",
    "    4. Email:\n",
    "    so collect the above details from the user query and return it.\n",
    "    \n",
    "    STRICTLY FOLLOW THE INSTRUCTIONS:\n",
    "    parse the available and given instructions only dont replace with anything for other input.\n",
    "    \n",
    "    Answer the user query. Wrap the output in `json` tags\\n{format_instructions}\n",
    "    \\n\"\"\"),\n",
    "    (\"user\", \"this is the user input:{query}\")]).partial(format_instructions=parser.get_format_instructions())\n",
    "    \n",
    "    \n",
    "    chain = prompt | llm | parser\n",
    "    query = \"create a lead jhon doe from antar crm with antar@gmail.com and the lead source is hentai the lead score is 7\"\n",
    "    result = chain.invoke({\"query\": query})\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\",\"\"\"You Are a CRM system details: extraxter agent you need to collect the following details from the given user query.\\n\\n\n",
    "    1. First Name: \n",
    "    2. Last Name: \n",
    "    3. Company: \n",
    "    4. Email:\n",
    "    so collect the above details from the user query and return it.\n",
    "    \n",
    "    STRICTLY FOLLOW THE INSTRUCTIONS:\n",
    "    parse the available data from the USER QUERY and give the structued result if result not found \n",
    "    DONT REPLACE WITH NONE. You can Replace with 'null'.\n",
    "    \n",
    "    Answer the user query. Wrap the output in `json` tags\\n{format_instructions}\n",
    "    \\n\"\"\"),\n",
    "    (\"user\", \"this is the user input:{query}\")]).partial(format_instructions=parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"description\": \"Complete details of a lead in a CRM system.\", \"properties\": {\"salutation\": {\"anyOf\": [{\"pattern\": \"^(Mr|Mrs|Ms|Dr)$\", \"type\": \"string\"}, {\"type\": \"null\"}], \"default\": \"null\", \"description\": \"Salutation of the lead.\", \"title\": \"Salutation\"}, \"first_name\": {\"description\": \"First name of the lead.\", \"maxLength\": 50, \"minLength\": 2, \"title\": \"First Name\", \"type\": \"string\"}, \"last_name\": {\"description\": \"Last name of the lead.\", \"maxLength\": 50, \"minLength\": 2, \"title\": \"Last Name\", \"type\": \"string\"}, \"company\": {\"description\": \"Company name of the lead.\", \"maxLength\": 100, \"title\": \"Company\", \"type\": \"string\"}, \"email\": {\"description\": \"Email address of the lead.\", \"pattern\": \"^\\\\\\\\S+@\\\\\\\\S+\\\\\\\\.\\\\\\\\S+$\", \"title\": \"Email\", \"type\": \"string\"}, \"gender\": {\"anyOf\": [{\"pattern\": \"^(Male|Female|Other)$\", \"type\": \"string\"}, {\"type\": \"null\"}], \"default\": \"null\", \"title\": \"Gender\"}, \"lead_source\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"default\": \"null\", \"description\": \"Lead source of the lead.\", \"title\": \"Lead Source\"}, \"lead_score\": {\"anyOf\": [{\"maximum\": 100, \"minimum\": 0, \"type\": \"integer\"}, {\"type\": \"null\"}], \"default\": 0, \"description\": \"Lead score of the lead.\", \"title\": \"Lead Score\"}, \"lead_value\": {\"anyOf\": [{\"ge\": 0, \"type\": \"string\"}, {\"type\": \"null\"}], \"default\": \"null\", \"description\": \"Lead value of the lead.\", \"title\": \"Lead Value\"}, \"website\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"default\": \"null\", \"description\": \"Website of the lead.\", \"title\": \"Website\"}, \"status\": {\"default\": \"new\", \"description\": \"Status of the lead.\", \"pattern\": \"^(new|contacted|qualified|lost)$\", \"title\": \"Status\", \"type\": \"string\"}, \"converted\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"default\": 0, \"description\": \"Converted status of the lead.\", \"title\": \"Converted\"}, \"revenue\": {\"anyOf\": [{\"minimum\": 0, \"type\": \"integer\"}, {\"type\": \"null\"}], \"default\": 0, \"description\": \"Revenue of the lead.\", \"title\": \"Revenue\"}, \"company_constitution\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"default\": \"null\", \"description\": \"Company constitution of the lead.\", \"title\": \"Company Constitution\"}, \"company_incorporation_date\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"default\": \"null\", \"description\": \"Company incorporation date of the lead.\", \"title\": \"Company Incorporation Date\"}, \"mobile_code\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"default\": \"null\", \"description\": \"Mobile code of the lead.\", \"title\": \"Mobile Code\"}, \"mobile_no\": {\"anyOf\": [{\"maxLength\": 15, \"minLength\": 10, \"type\": \"string\"}, {\"type\": \"null\"}], \"default\": \"null\", \"description\": \"Mobile number of the lead.\", \"title\": \"Mobile No\"}, \"employees\": {\"anyOf\": [{\"minimum\": 0, \"type\": \"integer\"}, {\"type\": \"null\"}], \"default\": 0, \"description\": \"Number of employees of the lead.\", \"title\": \"Employees\"}, \"territory_id\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"default\": \"null\", \"description\": \"Territory ID of the lead.\", \"title\": \"Territory Id\"}, \"industry_id\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"default\": \"null\", \"description\": \"Industry ID of the lead.\", \"title\": \"Industry Id\"}, \"department_id\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"default\": \"null\", \"description\": \"Department ID of the lead.\", \"title\": \"Department Id\"}}, \"required\": [\"first_name\", \"last_name\", \"company\", \"email\"]}\\n```'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "endpoint = os.getenv(\"AZURE_INFERENCE_SDK_ENDPOINT\", \"your_endpoint_here\")\n",
    "model_name = os.getenv(\"DEPLOYMENT_NAME\", \"Meta-Llama-3-8B-Instruct\")\n",
    "key = os.getenv(\"AZURE_INFERENCE_SDK_KEY\", \"YOUR_KEY_HERE\")\n",
    "client = ChatCompletionsClient(endpoint=endpoint, credential=AzureKeyCredential(key))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-azure-ai\n",
      "  Downloading langchain_azure_ai-0.1.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.10.0 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from langchain-azure-ai) (3.11.11)\n",
      "Requirement already satisfied: azure-ai-inference<2.0.0,>=1.0.0b7 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from azure-ai-inference[opentelemetry]<2.0.0,>=1.0.0b7->langchain-azure-ai) (1.0.0b9)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.32.0 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from langchain-azure-ai) (1.32.0)\n",
      "Collecting azure-cosmos<5.0.0,>=4.9.0 (from langchain-azure-ai)\n",
      "  Downloading azure_cosmos-4.9.0-py3-none-any.whl.metadata (80 kB)\n",
      "Requirement already satisfied: azure-identity<2.0.0,>=1.15.0 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from langchain-azure-ai) (1.21.0)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from langchain-azure-ai) (0.3.37)\n",
      "Requirement already satisfied: langchain-openai<0.4.0,>=0.3.0 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from langchain-azure-ai) (0.3.1)\n",
      "Collecting numpy<2.0,>=1.24 (from langchain-azure-ai)\n",
      "  Using cached numpy-1.26.4-cp313-cp313-macosx_15_0_arm64.whl\n",
      "Collecting pymongo<5.0.0,>=4.5.0 (from langchain-azure-ai)\n",
      "  Downloading pymongo-4.11.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (22 kB)\n",
      "Collecting simsimd<7.0.0,>=6.0.0 (from langchain-azure-ai)\n",
      "  Downloading simsimd-6.2.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (66 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.10.0->langchain-azure-ai) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.10.0->langchain-azure-ai) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.10.0->langchain-azure-ai) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.10.0->langchain-azure-ai) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.10.0->langchain-azure-ai) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.10.0->langchain-azure-ai) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.10.0->langchain-azure-ai) (1.18.3)\n",
      "Requirement already satisfied: isodate>=0.6.1 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from azure-ai-inference<2.0.0,>=1.0.0b7->azure-ai-inference[opentelemetry]<2.0.0,>=1.0.0b7->langchain-azure-ai) (0.7.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from azure-ai-inference<2.0.0,>=1.0.0b7->azure-ai-inference[opentelemetry]<2.0.0,>=1.0.0b7->langchain-azure-ai) (4.12.2)\n",
      "Collecting azure-core-tracing-opentelemetry (from azure-ai-inference[opentelemetry]<2.0.0,>=1.0.0b7->langchain-azure-ai)\n",
      "  Downloading azure_core_tracing_opentelemetry-1.0.0b11-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: requests>=2.21.0 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from azure-core<2.0.0,>=1.32.0->langchain-azure-ai) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from azure-core<2.0.0,>=1.32.0->langchain-azure-ai) (1.16.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from azure-identity<2.0.0,>=1.15.0->langchain-azure-ai) (44.0.0)\n",
      "Requirement already satisfied: msal>=1.30.0 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from azure-identity<2.0.0,>=1.15.0->langchain-azure-ai) (1.31.1)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from azure-identity<2.0.0,>=1.15.0->langchain-azure-ai) (1.2.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-azure-ai) (0.2.11)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-azure-ai) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-azure-ai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-azure-ai) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-azure-ai) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-azure-ai) (2.10.5)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from langchain-openai<0.4.0,>=0.3.0->langchain-azure-ai) (1.59.9)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from langchain-openai<0.4.0,>=0.3.0->langchain-azure-ai) (0.8.0)\n",
      "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=4.5.0->langchain-azure-ai)\n",
      "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from cryptography>=2.5->azure-identity<2.0.0,>=1.15.0->langchain-azure-ai) (1.17.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain-azure-ai) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.0->langchain-azure-ai) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.0->langchain-azure-ai) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.0->langchain-azure-ai) (1.0.0)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity<2.0.0,>=1.15.0->langchain-azure-ai) (2.10.1)\n",
      "Requirement already satisfied: portalocker<3,>=1.4 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from msal-extensions>=1.2.0->azure-identity<2.0.0,>=1.15.0->langchain-azure-ai) (2.10.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai<0.4.0,>=0.3.0->langchain-azure-ai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai<0.4.0,>=0.3.0->langchain-azure-ai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai<0.4.0,>=0.3.0->langchain-azure-ai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai<0.4.0,>=0.3.0->langchain-azure-ai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai<0.4.0,>=0.3.0->langchain-azure-ai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.0->langchain-azure-ai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.0->langchain-azure-ai) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.32.0->langchain-azure-ai) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.32.0->langchain-azure-ai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.32.0->langchain-azure-ai) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.32.0->langchain-azure-ai) (2024.12.14)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from tiktoken<1,>=0.7->langchain-openai<0.4.0,>=0.3.0->langchain-azure-ai) (2024.11.6)\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.12.0 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from azure-core-tracing-opentelemetry->azure-ai-inference[opentelemetry]<2.0.0,>=1.0.0b7->langchain-azure-ai) (1.29.0)\n",
      "Requirement already satisfied: pycparser in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity<2.0.0,>=1.15.0->langchain-azure-ai) (2.22)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.0->langchain-azure-ai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.0->langchain-azure-ai) (0.14.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from opentelemetry-api<2.0.0,>=1.12.0->azure-core-tracing-opentelemetry->azure-ai-inference[opentelemetry]<2.0.0,>=1.0.0b7->langchain-azure-ai) (1.2.17)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from opentelemetry-api<2.0.0,>=1.12.0->azure-core-tracing-opentelemetry->azure-ai-inference[opentelemetry]<2.0.0,>=1.0.0b7->langchain-azure-ai) (8.5.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from deprecated>=1.2.6->opentelemetry-api<2.0.0,>=1.12.0->azure-core-tracing-opentelemetry->azure-ai-inference[opentelemetry]<2.0.0,>=1.0.0b7->langchain-azure-ai) (1.17.2)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api<2.0.0,>=1.12.0->azure-core-tracing-opentelemetry->azure-ai-inference[opentelemetry]<2.0.0,>=1.0.0b7->langchain-azure-ai) (3.20.2)\n",
      "Downloading langchain_azure_ai-0.1.2-py3-none-any.whl (44 kB)\n",
      "Downloading azure_cosmos-4.9.0-py3-none-any.whl (303 kB)\n",
      "Downloading pymongo-4.11.2-cp313-cp313-macosx_11_0_arm64.whl (949 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m949.3/949.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading simsimd-6.2.1-cp313-cp313-macosx_11_0_arm64.whl (93 kB)\n",
      "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "Downloading azure_core_tracing_opentelemetry-1.0.0b11-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: simsimd, numpy, dnspython, pymongo, azure-cosmos, azure-core-tracing-opentelemetry, langchain-azure-ai\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.2\n",
      "    Uninstalling numpy-2.2.2:\n",
      "      Successfully uninstalled numpy-2.2.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "qdrant-client 1.13.2 requires numpy>=2.1.0; python_version >= \"3.13\", but you have numpy 1.26.4 which is incompatible.\n",
      "browser-use 0.1.26 requires langchain==0.3.14, but you have langchain 0.3.19 which is incompatible.\n",
      "browser-use 0.1.26 requires langchain-ollama==0.2.2, but you have langchain-ollama 0.2.3 which is incompatible.\n",
      "transformers 4.48.1 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed azure-core-tracing-opentelemetry-1.0.0b11 azure-cosmos-4.9.0 dnspython-2.7.0 langchain-azure-ai-0.1.2 numpy-1.26.4 pymongo-4.11.2 simsimd-6.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langchain-azure-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Here's one:\\n\\nWhy couldn't the bicycle stand up by itself? 🚴\\u200d♂️\\n\\nBecause it was two-tired! 😴👀\\n\\nHope that made you laugh! 😄\", additional_kwargs={}, response_metadata={'model': 'Meta-Llama-3-8B-Instruct', 'token_usage': {'input_tokens': 18, 'output_tokens': 44, 'total_tokens': 62}, 'finish_reason': 'stop'}, id='run-114bd73b-748f-4b5b-be73-b0302274dc39-0', usage_metadata={'input_tokens': 18, 'output_tokens': 44, 'total_tokens': 62})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_azure_ai.chat_models import AzureAIChatCompletionsModel\n",
    "\n",
    "llm = AzureAIChatCompletionsModel(\n",
    "    model_name=model_name,\n",
    "    credential=AzureKeyCredential(key),\n",
    "    endpoint=endpoint,\n",
    "    temperature=0.1,\n",
    "    \n",
    ")\n",
    "\n",
    "llm.invoke('Tell me a joke and include some emojis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "chat_llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.2,\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'salutation': None,\n",
       " 'first_name': 'Jhon',\n",
       " 'last_name': None,\n",
       " 'company': 'create a lead',\n",
       " 'email': None,\n",
       " 'gender': None,\n",
       " 'lead_source': None,\n",
       " 'lead_score': 0,\n",
       " 'lead_value': None,\n",
       " 'website': None,\n",
       " 'status': 'new',\n",
       " 'converted': 0,\n",
       " 'revenue': 0,\n",
       " 'company_constitution': None,\n",
       " 'company_incorporation_date': None,\n",
       " 'mobile_code': None,\n",
       " 'mobile_no': None,\n",
       " 'employees': 0,\n",
       " 'territory_id': None,\n",
       " 'industry_id': None,\n",
       " 'department_id': None}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm | parser\n",
    "query = \"create a lead jhon\"\n",
    "result = chain.invoke({\"query\": query})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "colleceted_data: dict = {}\n",
    "colleceted_data.update(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_LeadData = LeadDetails(**colleceted_data).model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'salutation': None,\n",
       " 'first_name': 'Jhon',\n",
       " 'last_name': 'Doe',\n",
       " 'company': 'Extraxter',\n",
       " 'email': 'jhon.doe@extraxter.com',\n",
       " 'gender': None,\n",
       " 'lead_source': None,\n",
       " 'lead_score': 0,\n",
       " 'lead_value': None,\n",
       " 'website': None,\n",
       " 'status': 'new',\n",
       " 'converted': 0,\n",
       " 'revenue': 0,\n",
       " 'company_constitution': None,\n",
       " 'company_incorporation_date': None,\n",
       " 'mobile_code': None,\n",
       " 'mobile_no': None,\n",
       " 'employees': 0,\n",
       " 'territory_id': None,\n",
       " 'industry_id': None,\n",
       " 'department_id': None}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_LeadData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "ename": "_IncompleteInputError",
     "evalue": "incomplete input (237004170.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[217], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    def missing_fields():\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31m_IncompleteInputError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "def missing_fields(colleceted_data, required_fields):\n",
    "    missing_fields = []\n",
    "    for field in required_fields:\n",
    "        if field not in colleceted_data:\n",
    "            missing_fields.append(field)\n",
    "    return missing_fields\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input():\n",
    "    MANDATORY_FIELDS = [\"first_name\", \"last_name\", \"company\", \"email\"]\n",
    "    colleceted_data: dict = {}\n",
    "    \n",
    "    while True:\n",
    "        missing_fields = missing_fields(colleceted_data, MANDATORY_FIELDS)\n",
    "        if missing_fields:\n",
    "            query = input(f\"Enter the required Data {','.join(missing_fields)}: \")\n",
    "            result = chain.invoke({\"query\": query})\n",
    "            colleceted_data.update(result)\n",
    "        if not missing_fields:\n",
    "            if input(\"Do you want to add more details? (y/n): \").lower() == \"n\":\n",
    "                break\n",
    "            else:\n",
    "                query = input(\"Enter the Data: \")\n",
    "                result = chain.invoke({\"query\": query})\n",
    "                colleceted_data.update(result)\n",
    "    return colleceted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "def decide_intent(state: State):\n",
    "    \n",
    "    \"Decide the operation to be performed based on the user query.\"\n",
    "    \n",
    "    system_message = \"\"\"You are a CRM System Manager for Antar CRM.\n",
    "    Here There are several operations CREATE, READ, UPDATE and DELETE.\n",
    "    User input will pass through the system and you need to decide which operation to perform.\n",
    "    \n",
    "    FOR EXAMPLE:\n",
    "      If the user says create lead or any other querys related to the creation of operations then you need to perform the create operation.\n",
    "      likewise you need to do perfrom all the other four operations are create read update and delete.\n",
    "      \n",
    "    YOUR TASK:\n",
    "        1. Extract the operation from the user query.\n",
    "        2. Return the operation name.\n",
    "        if related to create then it return with 'create' and so on.\n",
    "        if the task is not related to any of the above operations then return 'unkonwn'.\n",
    "      \"\"\"\n",
    "      \n",
    "    prompt = ChatPromptTemplate([\n",
    "        (\"system\", system_message),\n",
    "        (\"user\", \"this is the user input:{query}\")])\n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\"query\": state['query']})\n",
    "    response = response.content.strip().lower()\n",
    "    if response != 'unknown':\n",
    "        state['decision'] = response\n",
    "    else:\n",
    "        state['decision'] = 'unknown'\n",
    "    return state\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure.identity\n",
      "  Downloading azure_identity-1.21.0-py3-none-any.whl.metadata (81 kB)\n",
      "Collecting azure-ai-inference\n",
      "  Downloading azure_ai_inference-1.0.0b9-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting azure-core>=1.31.0 (from azure.identity)\n",
      "  Downloading azure_core-1.32.0-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: cryptography>=2.5 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from azure.identity) (44.0.0)\n",
      "Collecting msal>=1.30.0 (from azure.identity)\n",
      "  Downloading msal-1.31.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting msal-extensions>=1.2.0 (from azure.identity)\n",
      "  Downloading msal_extensions-1.2.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from azure.identity) (4.12.2)\n",
      "Collecting isodate>=0.6.1 (from azure-ai-inference)\n",
      "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: requests>=2.21.0 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from azure-core>=1.31.0->azure.identity) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from azure-core>=1.31.0->azure.identity) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from cryptography>=2.5->azure.identity) (1.17.1)\n",
      "Collecting PyJWT<3,>=1.0.0 (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure.identity)\n",
      "  Using cached PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: portalocker<3,>=1.4 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from msal-extensions>=1.2.0->azure.identity) (2.10.1)\n",
      "Requirement already satisfied: pycparser in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from cffi>=1.12->cryptography>=2.5->azure.identity) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure.identity) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure.identity) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure.identity) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/a2024/miniforge3/envs/generativeai/lib/python3.13/site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure.identity) (2024.12.14)\n",
      "Downloading azure_identity-1.21.0-py3-none-any.whl (189 kB)\n",
      "Downloading azure_ai_inference-1.0.0b9-py3-none-any.whl (124 kB)\n",
      "Downloading azure_core-1.32.0-py3-none-any.whl (198 kB)\n",
      "Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
      "Downloading msal-1.31.1-py3-none-any.whl (113 kB)\n",
      "Downloading msal_extensions-1.2.0-py3-none-any.whl (19 kB)\n",
      "Using cached PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: PyJWT, isodate, azure-core, azure-ai-inference, msal, msal-extensions, azure.identity\n",
      "Successfully installed PyJWT-2.10.1 azure-ai-inference-1.0.0b9 azure-core-1.32.0 azure.identity-1.21.0 isodate-0.7.2 msal-1.31.1 msal-extensions-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install azure.identity azure-ai-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"Seattle! Such a great city! Here are three must-visit attractions in Seattle:\\n\\n1. **The Space Needle**: This iconic 605-foot tall tower is a symbol of Seattle and offers breathtaking 360-degree views of the city, Puget Sound, and the surrounding mountains. You can take a elevator ride to the top for panoramic views and learn about the history of the tower through interactive exhibits.\\n2. **Pike Place Market**: This historic farmers market is a must-visit for foodies and shoppers alike. You can sample local foods, watch fishmongers in action, and browse through stalls selling fresh produce, crafts, and souvenirs. Be sure to check out the original Starbucks store, which is located nearby.\\n3. **The Chihuly Garden and Glass**: This unique attraction showcases the stunning glass artwork of Dale Chihuly in a beautiful garden setting. The exhibit features hundreds of Chihuly's pieces, including sculptures, installations, and interactive displays. You can also explore the glasshouse, which offers a serene atmosphere and a chance to see artists at work.\\n\\nThese three attractions offer a great taste of Seattle's culture, history, and natural beauty. Enjoy your visit to Seattle!\",\n",
      "        \"role\": \"assistant\",\n",
      "        \"tool_calls\": []\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1741803297,\n",
      "  \"id\": \"cmpl-83c809d98f684d11bcd6c659ebb42795\",\n",
      "  \"model\": \"Meta-Llama-3-8B-Instruct\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 244,\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"total_tokens\": 275\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "endpoint = os.getenv(\"AZURE_INFERENCE_SDK_ENDPOINT\", \"https://azurefoundry4137253792.services.ai.azure.com/models\")\n",
    "model_name = os.getenv(\"DEPLOYMENT_NAME\", \"Meta-Llama-3-8B-Instruct\")\n",
    "key = os.getenv(\"AZURE_INFERENCE_SDK_KEY\", \"YOUR_KEY_HERE\")\n",
    "client = ChatCompletionsClient(endpoint=endpoint, credential=AzureKeyCredential(key))\n",
    "\n",
    "response = client.complete(\n",
    "  messages=[\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    UserMessage(content=\"What are 3 things to visit in Seattle?\")\n",
    "  ],\n",
    "  model = model_name,\n",
    "  max_tokens=1000\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models.azureml_endpoint import AzureMLChatOnlineEndpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generativeai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
